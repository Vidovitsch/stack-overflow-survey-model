{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Job Satisfaction of Software Developers\n",
    "In this research project a classification model will be created that tries to predict the Job Satisfaction of Software Developers using the survey results from the Stack Overflow survey of 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Describing the dataset\n",
    "[Stack Overflow](https://stackoverflow.com/) is a website where you can ask and answer software related questions. It is a platform where millions of programmers, software developers, software engineers, etc. meet every day to learn form each other. Stack Overflow itself is aware of the enormous popularity of their platform and for this reason they keep a annual survey to get general insight about the average software engineer in relation to his/her field of work.\n",
    "\n",
    "Every year the results of the survey will get published on their website (cleaned and in csv format). Multiple datasets (one for each year since 2015) are available for analysis. For this project the survey results of 2018 will be used exclusively. The main reason for this choice is recency and the completeness of the results. The 2018 survey results were filled in by around 100.000 software developers, most of which answered 129 different questions. These questions are about job satisfaction, salary, favourite programming languages, weekly exercise, company size, etc. This large variety of questions provides a source of interesting research opportunities.\n",
    "\n",
    "**Source of the dataset**<br />\n",
    "Stack Overflow Developer Survey 2018 (186 MB): https://www.kaggle.com/stackoverflow/stack-overflow-2018-developer-survey\n",
    "\n",
    "\n",
    "**Data description:**<br />\n",
    "The Stack Overflow survey results of 2018 has in total 98855 rows and 129 columns. Some of these columns consist of only numerical data like 'Salary' and 'ConvertedSalary', while all the other columns are categorical (nominal or ordinal). The categorical columns are devidable over three data types:\n",
    "- Values denoted in text. E.g. 'Yes', 'No', 'United States', 'Employed part-time', etc.\n",
    "- Values denoted in ';' seperated lists. E.g. 'Python;Java;C#', 'Windows;Linux;, etc.\n",
    "- Values denoted in numbers. E.g. 1, 2, 3, 4, etc. (for rankings)\n",
    "\n",
    "Textual input can't be interpreted easily by the average Machine Learning algorithm. Therefore, preprocessing of the original dataset is needed, so it can be used for further analysis. A [notebook](./dataset_preprocessing.ipynb) is created that is dedicted to preprocessing the Stack Overflow survey dataset in the following ways:\n",
    "- Drop rows with missing values in the column 'JobSatisfaction'. The column 'JobSatisfaction' is the target value that will be used for analysis. It is not desirable to have missing values for a target feature, because the value NaN doesn't refer to valid classification value.\n",
    "- Drop unimportant columns. Some columns can be left out because they have no correlation with the target column 'JobSatisfaction', are redundant or have too many missing values (35% or higher).\n",
    "- Preprocess values dentoed in ';' seperated lists. List values such as 'Python;Java;C#' can't be used as input for a Machine Learning algorithm. First, the value has to be numerical. Second, numerification of the ';' value as is will result a unique class for every unique list. It is instead needed to get a unique class for every language present in the list.\n",
    "- Encode text to numerical values. Text isn't easy to interpret for Machine Learning algorithms. To solve this problem all text-formatted values will be converted to numerical values. Nominal values are encoded with One Hot Encoding, while ordinal values are encoded with manually added labels.\n",
    "- Impute missing values. A lot of data is missing, this missing data can be imputed with statistical values (e.g. mean, mode, etc.)\n",
    "\n",
    "The above steps will result in a preprocessed data set with 69276 rows and 623 columns.<br />\n",
    "The data will be tranformed as follows:<br />\n",
    "\n",
    "| Student | Programming Language | Country        |\n",
    "|:-------:|:--------------------:|:--------------:|\n",
    "| Yes     | Python;Java;C#       | Kenya          |\n",
    "| No      | Python;C#            | United Kingdom |\n",
    "| Yes     | Java;C#              | United States  |\n",
    "\n",
    "| Student | Python | Java | C# | Country%Kenya | Country%United Kingdom | Country%United States |\n",
    "|:-------:|:------:|:----:|:--:|:-------------:|:----------------------:|:---------------------:|\n",
    "| 1       | 1      | 1    | 1  | 1             | 0                      | 0                     |\n",
    "| 0       | 1      | 0    | 1  | 0             | 1                      | 0                     |\n",
    "| 1       | 0      | 1    | 1  | 0             | 0                      | 1                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining research\n",
    "Research will be conducted on the job satisfaction of software developers. The dataset, as described above, will be used to create a classifaction model that predicts the job statisfaction of software developers. The following research question will be answered:\n",
    "\n",
    "**Can an accurate model be created, given the features denoted in the survey, to predict the job satisfaction of software developers?**\n",
    "\n",
    "The model will be seen as accurate if at least 90% of the predictions are the same as the target values (column 'JobSatisfaction'). On top of the research question, a initial hypothesis can be made:\n",
    "\n",
    "**Salary and career satisfaction are the main influencors of job satisfaction, and is therefore responsible for a high accuracy classification model.**\n",
    "\n",
    "This hypothesis will be either approved or rejected accoring to the reseach results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset exploration\n",
    "Initial exploration of the data gives insight of the data itself and a better intuiting while conducting the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# disable chained assignments\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Import the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed dataset\n",
    "so_survey = pd.read_csv('./dataset/so_survey_prepped.csv')\n",
    "\n",
    "# Import the mappings for decoding purposes\n",
    "so_mappings = pd.read_csv('./dataset/so_survey_mappings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>YearsCoding</th>\n",
       "      <th>YearsCodingProf</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>CareerSatisfaction</th>\n",
       "      <th>AssessJob1</th>\n",
       "      <th>AssessJob2</th>\n",
       "      <th>AssessJob3</th>\n",
       "      <th>AssessJob4</th>\n",
       "      <th>AssessJob5</th>\n",
       "      <th>...</th>\n",
       "      <th>EducationParents%Bachelor’s degree (BA, BS, B.Eng., etc.)</th>\n",
       "      <th>EducationParents%Master’s degree (MA, MS, M.Eng., MBA, etc.)</th>\n",
       "      <th>EducationParents%Other doctoral degree (Ph.D, Ed.D., etc.)</th>\n",
       "      <th>EducationParents%Primary/elementary school</th>\n",
       "      <th>EducationParents%Professional degree (JD, MD, etc.)</th>\n",
       "      <th>EducationParents%Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)</th>\n",
       "      <th>EducationParents%Some college/university study without earning a degree</th>\n",
       "      <th>EducationParents%They never completed any formal education</th>\n",
       "      <th>Dependents%No</th>\n",
       "      <th>Dependents%Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CompanySize  YearsCoding  YearsCodingProf  JobSatisfaction  \\\n",
       "0          2.0          1.0                1                6   \n",
       "1          7.0          9.0                5                1   \n",
       "2          2.0          7.0                2                5   \n",
       "\n",
       "   CareerSatisfaction  AssessJob1  AssessJob2  AssessJob3  AssessJob4  \\\n",
       "0                   6        10.0         7.0         8.0         1.0   \n",
       "1                   3         1.0         7.0        10.0         8.0   \n",
       "2                   5         9.0         9.0         8.0         1.0   \n",
       "\n",
       "   AssessJob5       ...        \\\n",
       "0         2.0       ...         \n",
       "1         2.0       ...         \n",
       "2         1.0       ...         \n",
       "\n",
       "   EducationParents%Bachelor’s degree (BA, BS, B.Eng., etc.)  \\\n",
       "0                                                1.0           \n",
       "1                                                1.0           \n",
       "2                                                1.0           \n",
       "\n",
       "   EducationParents%Master’s degree (MA, MS, M.Eng., MBA, etc.)  \\\n",
       "0                                                0.0              \n",
       "1                                                0.0              \n",
       "2                                                0.0              \n",
       "\n",
       "   EducationParents%Other doctoral degree (Ph.D, Ed.D., etc.)  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "\n",
       "   EducationParents%Primary/elementary school  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "\n",
       "   EducationParents%Professional degree (JD, MD, etc.)  \\\n",
       "0                                                0.0     \n",
       "1                                                0.0     \n",
       "2                                                0.0     \n",
       "\n",
       "   EducationParents%Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)  \\\n",
       "0                                                0.0                                                     \n",
       "1                                                0.0                                                     \n",
       "2                                                0.0                                                     \n",
       "\n",
       "   EducationParents%Some college/university study without earning a degree  \\\n",
       "0                                                0.0                         \n",
       "1                                                0.0                         \n",
       "2                                                0.0                         \n",
       "\n",
       "   EducationParents%They never completed any formal education  Dependents%No  \\\n",
       "0                                                0.0                     0.0   \n",
       "1                                                0.0                     0.0   \n",
       "2                                                0.0                     1.0   \n",
       "\n",
       "   Dependents%Yes  \n",
       "0             1.0  \n",
       "1             1.0  \n",
       "2             0.0  \n",
       "\n",
       "[3 rows x 623 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first three entries of so_survey data frame\n",
    "so_survey.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>YearsCoding</th>\n",
       "      <th>YearsCodingProf</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>CareerSatisfaction</th>\n",
       "      <th>TimeFullyProductive</th>\n",
       "      <th>AgreeDisagree1</th>\n",
       "      <th>AgreeDisagree2</th>\n",
       "      <th>AgreeDisagree3</th>\n",
       "      <th>NumberMonitors</th>\n",
       "      <th>...</th>\n",
       "      <th>HypotheticalTools1</th>\n",
       "      <th>HypotheticalTools2</th>\n",
       "      <th>HypotheticalTools3</th>\n",
       "      <th>HypotheticalTools4</th>\n",
       "      <th>HypotheticalTools5</th>\n",
       "      <th>HoursComputer</th>\n",
       "      <th>HoursOutside</th>\n",
       "      <th>SkipMeals</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fewer than 10 employees</td>\n",
       "      <td>0-2 years</td>\n",
       "      <td>0-2 years</td>\n",
       "      <td>Extremely dissatisfied</td>\n",
       "      <td>Extremely dissatisfied</td>\n",
       "      <td>Less than a month</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Less than 1 hour</td>\n",
       "      <td>Less than 30 minutes</td>\n",
       "      <td>Never</td>\n",
       "      <td>I don't typically exercise</td>\n",
       "      <td>Under 18 years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 to 19 employees</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>Moderately dissatisfied</td>\n",
       "      <td>Moderately dissatisfied</td>\n",
       "      <td>One to three months</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>1 - 4 hours</td>\n",
       "      <td>30 - 59 minutes</td>\n",
       "      <td>1 - 2 times per week</td>\n",
       "      <td>1 - 2 times per week</td>\n",
       "      <td>18 - 24 years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>6-8 years</td>\n",
       "      <td>6-8 years</td>\n",
       "      <td>Slightly dissatisfied</td>\n",
       "      <td>Slightly dissatisfied</td>\n",
       "      <td>Three to six months</td>\n",
       "      <td>Neither Agree nor Disagree</td>\n",
       "      <td>Neither Agree nor Disagree</td>\n",
       "      <td>Neither Agree nor Disagree</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>5 - 8 hours</td>\n",
       "      <td>1 - 2 hours</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>25 - 34 years old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CompanySize YearsCoding YearsCodingProf  \\\n",
       "0  Fewer than 10 employees   0-2 years       0-2 years   \n",
       "1       10 to 19 employees   3-5 years       3-5 years   \n",
       "2       20 to 99 employees   6-8 years       6-8 years   \n",
       "\n",
       "           JobSatisfaction       CareerSatisfaction  TimeFullyProductive  \\\n",
       "0   Extremely dissatisfied   Extremely dissatisfied    Less than a month   \n",
       "1  Moderately dissatisfied  Moderately dissatisfied  One to three months   \n",
       "2    Slightly dissatisfied    Slightly dissatisfied  Three to six months   \n",
       "\n",
       "               AgreeDisagree1              AgreeDisagree2  \\\n",
       "0           Strongly disagree           Strongly disagree   \n",
       "1                    Disagree                    Disagree   \n",
       "2  Neither Agree nor Disagree  Neither Agree nor Disagree   \n",
       "\n",
       "               AgreeDisagree3 NumberMonitors         ...          \\\n",
       "0           Strongly disagree              1         ...           \n",
       "1                    Disagree              2         ...           \n",
       "2  Neither Agree nor Disagree              3         ...           \n",
       "\n",
       "        HypotheticalTools1       HypotheticalTools2       HypotheticalTools3  \\\n",
       "0    Not at all interested    Not at all interested    Not at all interested   \n",
       "1  A little bit interested  A little bit interested  A little bit interested   \n",
       "2      Somewhat interested      Somewhat interested      Somewhat interested   \n",
       "\n",
       "        HypotheticalTools4       HypotheticalTools5     HoursComputer  \\\n",
       "0    Not at all interested    Not at all interested  Less than 1 hour   \n",
       "1  A little bit interested  A little bit interested       1 - 4 hours   \n",
       "2      Somewhat interested      Somewhat interested       5 - 8 hours   \n",
       "\n",
       "           HoursOutside             SkipMeals                    Exercise  \\\n",
       "0  Less than 30 minutes                 Never  I don't typically exercise   \n",
       "1       30 - 59 minutes  1 - 2 times per week        1 - 2 times per week   \n",
       "2           1 - 2 hours  3 - 4 times per week        3 - 4 times per week   \n",
       "\n",
       "                  Age  \n",
       "0  Under 18 years old  \n",
       "1   18 - 24 years old  \n",
       "2   25 - 34 years old  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first three entries of so_mappings data frame\n",
    "so_mappings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create decode  and encode function\n",
    "In advance, a generic decode and encode function will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(labels, column_name, decoder=so_mappings):\n",
    "    \"\"\" Decodes encoded (preprocessed) labes using a decoder.\n",
    "    E.g. [0, 1, 0, 0] for column 'Hobby' => ['Yes', 'No', 'Yes', 'Yes']\n",
    "    \"\"\"\n",
    "    decoded_labels = so_mappings[column_name].values\n",
    "    return [decoded_labels[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, column_name, encoder=so_mappings):\n",
    "    \"\"\" Encoded decoded labes using an encoder.\n",
    "    E.g. ['Yes', 'No', 'Yes', 'Yes'] for column 'Hobby' => [0, 1, 0, 0]\n",
    "    \"\"\"\n",
    "    decoded_labels = so_mappings[column_name].values.tolist()\n",
    "    return [decoded_labels.index(l) for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Distribution of salary\n",
    "Lets see how salary is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data frame with column 'ConvertedSalary' and NaN values filtered out\n",
    "mask = pd.isnull(so_survey['ConvertedSalary']) == False\n",
    "salaries = so_survey['ConvertedSalary'][mask].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot salary distribution\n",
    "plt.figure(figsize=(20,5))\n",
    "kde = sns.kdeplot(salaries, shade=True)\n",
    "kde.set(title='Data distribution of salary', \n",
    "        xlabel='Salary', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of salary appears the be very skewed. To reduce the skew, log transformation can be applied on the salaries. But before we can do this, the salaries with value zero needs to be filtered out (logarithm of zero is impossible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = np.log(salaries[salaries != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot salary distribution (log transformed)\n",
    "plt.figure(figsize=(20,5))\n",
    "kde = sns.kdeplot(salaries, shade=True)\n",
    "kde.set(title='Data distribution of salary (log transformed)', \n",
    "        xlabel='Salary (log transformed)', \n",
    "        ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data distribution has now more the appearance of a gaussian distribution (bell curve shape). Although, the data is still skewed due to the outliers. If the many outliers will cause the classification model to perform badly, the outliers will be removed. This can be done, for example, by pruning the data by $x$ times the standard deviation of the salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Research strategy\n",
    "The research will be conducted by using following steps:\n",
    "1. Loosely optimize the hyperparameters of a classifier that will be used in the feature selection part. This prevents selecting features with e.g. an overfitted/underfit model.\n",
    "2. Selecting features with the finetuned classifier. (feature selection is necessary since training classifiers with 409 features and more than 10000 rows is extremely time consuming) \n",
    "3. Use the selected features to train and optimize different Machine Learning algorithms.\n",
    "4. Compare the performance of the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target (y) \n",
    "target = 'JobSatisfaction'\n",
    "y = so_survey[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features (X)\n",
    "features = [x for x in so_survey.columns if x != target]\n",
    "X = so_survey[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Perform feature scaling\n",
    "The column 'ConvertedSalary' will be log tranformed to reduce skewness. Also, a min max scaler will be used to scale the features to values between 0 and 1, resulting in all features having values within the same range. This has some benefits:\n",
    "+ All features have the same 'weight'. This will help algorithms like SVM (with Gaussian kernel) and K-means to perform better.\n",
    "+ Speeds up Gradient Descent while training.\n",
    "+ Improves insight in coefficients. If all features have the same 'weight', the resulting coefficients will describe the influence of feature on the target better. This is useful for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the logarithm of 0 is impossible.\n",
    "# For this reason the values of 0 will be replaced by 0.1.\n",
    "X['ConvertedSalary'].loc[(X['ConvertedSalary'] == 0)] = 0.1\n",
    "\n",
    "# Perform log transformation on the values in the column 'ConvertedSalary'\n",
    "X['ConvertedSalary'] = np.log(X['ConvertedSalary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature scaling with min max scaler\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Get training and testing sets\n",
    "The features and target values will be split into training and testing sets.\n",
    "The training set will contain 75% of the dataset (randomly selected rows).\n",
    "The testing set will therefore contain 25% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loosely optimize estimator\n",
    "The Random Forest classifier will be used as an estimator for the feature selection step. This has the following benefits:\n",
    "+ Popular feature selection algorithms like RFE or RFECV are recursively training a classifier. This will take a lot of time. Decision Trees are faster than classifiers such as Neural Networks or Support Vector Machines. \n",
    "+ By using a Random Forest the main drawback of Decision Trees (overfitting the training set) will be (partly) solved.\n",
    "+ It isn't known if the classes are linear separatable. A Random Forest is both a linear and a non-linear classifier.\n",
    "<br><br>The RandomizedSearch method will be used in contrast to GridSearch, because RandomizedSearch doesn't compute all possible computations (hence 'loosely') and is therefore computationally less expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest classifier and RandomizedSearchCV algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: [ 50 100 150 200]\n",
      "max_depth: [5]\n",
      "min_samples_split: [ 50  55  60  65  70  75  80  85  90  95 100]\n",
      "min_samples_leaf: [20 25 30 35 40 45 50]\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid with hyperparameter ranges\n",
    "random_grid = { 'n_estimators': np.arange(50, 250, 50),\n",
    "                'max_depth': [5],\n",
    "                'min_samples_split': np.arange(50, 105, 5),\n",
    "                'min_samples_leaf': np.arange(20, 55, 5) }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in random_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the default estimator: 0.358\n"
     ]
    }
   ],
   "source": [
    "# Train default Random Forest classifier for comparison\n",
    "default_score = np.sum(cross_val_score(RandomForestClassifier(random_state=21), X, y, cv=5)) / 5\n",
    "\n",
    "# Print default cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the default estimator: %0.3f' % (default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  6.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Random Search of optimal set of hyperparameters using 3 fold cross validation and 25 different combinations. \n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=21), \n",
    "                                   param_distributions=random_grid, \n",
    "                                   n_iter=25, \n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=21, \n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random Search on the training set\n",
    "random_search = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 0.373\n",
      "Improvement relative to default mean cross-validated score: : 0.015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'min_samples_split': 55,\n",
       " 'min_samples_leaf': 20,\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print best cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the best estimator: %0.3f' % (random_search.best_score_))\n",
    "\n",
    "# Print improvements relative to Random Forest classfier with default hyperparameters\n",
    "improvement = random_search.best_score_ - default_score\n",
    "print('Improvement relative to default mean cross-validated accuracy: : %0.3f' % (improvement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature selection\n",
    "The datasets contains 622 features and about 69000 rows. Training with such an amount of features can take a very long time for algorithms like SVM (expontential time complexity). The training process becomes much faster by pruning redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. RFECV (Recursive Feature Elimination with Cross-Validation)\n",
    "Recursive Feature Elimination is a method that uses an estimator (in this case a classifier) that assigns weights to features (coefficients). The goal is to recursively select features by considering smaller and smaller sets of features. The least important features are pruned from the training and testing set. Cross Validation is used to make a selection of the best number of features.<br>\n",
    "The estimator that will be used is the Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RFECV algorithm\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RFECV algorithm with the loosely optimized Random Forest classifier\n",
    "f_selector = RFECV(estimator=random_search.best_estimator_ ,\n",
    "                   step=1,\n",
    "                   cv=3,\n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RFECV on the training set\n",
    "f_selector = f_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of features vs. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.plot(range(1, len(f_selector.grid_scores_) + 1), f_selector.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best number of features\n",
    "print('Optimal number of features: %i' % (f_selector.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that shows the ranking of features\n",
    "def create_ranking_df(ranking_list, columns):\n",
    "    ranking = {}\n",
    "    for i in range(len(ranking_list)):\n",
    "        rank = ranking_list[i]\n",
    "        col = columns[i]\n",
    "        if rank in ranking:\n",
    "            ranking[rank].append(col)\n",
    "        else:\n",
    "            ranking[rank] = [col]\n",
    "    ranking = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in ranking.items()]))\n",
    "    return ranking.reindex(sorted(ranking.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show ranking\n",
    "ranking = create_ranking_df(f_selector.ranking_, X.columns)\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Prune redundant featues\n",
    "The selected features will be used to create the new training set and test set.\n",
    "CareerSatisfaction and ConvertedSalary will be added to the selection if they are not selected. This is because the two values are needed to promote or reject the defined hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indeces of best selection of features\n",
    "best_features = [i for i, rank in enumerate(f_selector.ranking_) if rank == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes of 'CareerSatisfaction' and 'ConvertedSalary'\n",
    "satisfaction = [i for i, col in enumerate(X.columns) if col == 'CareerSatisfaction'][0]\n",
    "salary= [i for i, col in enumerate(X.columns) if col == 'ConvertedSalary'][0]\n",
    "\n",
    "# If index is not yet in selection: add it to selection\n",
    "if satisfaction not in best_features: best_features.append(satisfaction)\n",
    "if salary not in best_features: best_features.append(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_columns = ['CareerSatisfaction',\n",
    "#                 'JobSearchStatus%I am actively looking for a job',\n",
    "#                 'JobSearchStatus%I am not interested in new job...',\n",
    "#                 'JobSearchStatus%I’m not actively looking, but ...',\n",
    "#                 'ConvertedSalary']\n",
    "#best_features = [i for i, column in  enumerate(X.columns) if column in dummy_columns]\n",
    "X_train_best = X_train[:,best_features]\n",
    "X_test_best = X_test[:,best_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train and optimize different algorithms\n",
    "In this section the following Machine Learning algorithms will be optimized and trained to predict job satisfaction:\n",
    "+ Random Forest (Classifier)\n",
    "+ Support Vector Machine\n",
    "+ Naive Bayes\n",
    "+ Random Forest (Regressor)\n",
    "+ K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV algorithm to select best combination of hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import leaning_curve and validation_curve to evaluate trained models\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting learning curves:\n",
    "# Learning curves show the learning rate of the training and \n",
    "# cross-validation set over training examples (m).\n",
    "def plot_learning_curve(estimator, title, X, y, scoring='accuracy'):    \n",
    "    # Fit to get parameters for the learning curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator,\n",
    "        X, y, cv=3, train_sizes=np.linspace(.1, 1.0, 5), scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Get mean and standard deviation for training scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    \n",
    "    # Get mean and standard deviation for cross-validation scores\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # Setup chart\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score (' + scoring + ')')\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color='b')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='r')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='b',\n",
    "             label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='Cross-validation score')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting validation curves:\n",
    "# Validation curves show the learning rate of the training and \n",
    "# cross-validation set over a range of values of a defined hyperparameter.\n",
    "def plot_validation_curve(estimator, title, X, y, param_range, param_name, scoring='accuracy'):\n",
    "    # Fit to get parameters for the validation curve\n",
    "    train_scores, test_scores = validation_curve(estimator,\n",
    "        X, y, cv=3, param_name=param_name, param_range=param_range, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Get mean and standard deviation for training scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "\n",
    "    # Get mean and standard deviation for cross-validation scores\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # Setup chart\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Score (' + scoring + ')')\n",
    "    plt.grid()\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='g', lw=2)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color='r', lw=2)\n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color='g',\n",
    "         label='Training score')\n",
    "    plt.plot(param_range, test_scores_mean, 'o-', color='r',\n",
    "             label='Cross-validation score')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_metrics(y_test, y_pred, show=True):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "    recall = recall_score(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "    if show:\n",
    "        print('Accuracy on test set: %0.3f' % (accuracy))\n",
    "        print('F1-score on test set: %0.3f' % (f1))\n",
    "        print('Precision on test set: %0.3f' % (precision))\n",
    "        print('Recall on test set: %0.3f' % (recall))\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Random Forest (Classifier)\n",
    "*Inherently multiclass*<br><br>\n",
    "The Random Forest classifier is used before when selecting features. This time the Random Forest classifier will be used to predict the job satisfaction using the selected features.\n",
    "First, the default Random Forest classifier will trained on the training set and evaluated.\n",
    "After the evaluation, a second Random Forest will be used to select the optimal hyperparameters.\n",
    "The Random Forest classifier containing the optimal hyperparamaters will be evaluated on high variance (overfitting), high bias (underfitting) and performance based on accuracy.<br>\n",
    "The following hyperparameters will be optimized:\n",
    "+ n_estimators: The number of trees in the forest.\n",
    "+ max_depth: The maximum depth of the tree.\n",
    "+ min_samples_split: The minimum number of samples required to split an internal node.\n",
    "+ min_samples_leaf: The minimum number of samples required to be at a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Training the default Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train default Random Forest classifier for comparison\n",
    "rf_clf_default = RandomForestClassifier(random_state=21)\n",
    "rf_clf_default_score = np.sum(cross_val_score(rf_clf_default, X_train_best, y_train, cv=5)) / 5\n",
    "\n",
    "# Print default cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the Random Forest classifier with default parameters: %0.3f' % (rf_clf_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show default cross-validated metrics\n",
    "rf_clf_default.fit(X_train_best, y_train)\n",
    "rf_clf_default_metrics = clf_metrics(y_test, rf_clf_default.predict(X_test_best));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(RandomForestClassifier(random_state=21), 'Learning Curves of Random Forest (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight high variance problem (overfitted) will occur when using the default Random Forest classifier. The training set starts of with high accuracy (as expected) but the accuracy doesn't decline much as the number of training examples increases. In contrast, the cross-validation accuracy starts off with low accuracy and increases with very small amounts as the number of training examples increases. This high variance problem can be solved by evaluating different hyperparameters of the Random Forest classifier and using the results to fine-tune the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Evaluate hyperparameters\n",
    "Show the validation curve of different hyperparamethers of the Random Forest classifiers (for both the training and cross-validation set). The results will be used to select a range of hyperparameter to perform Grid Search on, which will optimize the hyperparameters more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'n_estimators'\n",
    "n_estimators = np.arange(5, 505, 50)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'Random Forest accuracy for different values of n_estimator', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      n_estimators, \n",
    "                      'n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'n_estimators' seems to increase the accuracy of the training set between the values 0 and 100, which will add to the high variance problem. Also, increasing 'min_samples_split' doesn't seems to increase the accuracy of the cross-validation set very much. Becuase increasing 'n_estimators' doesn't seem te be necessary, the range between 10 and 200 will be used when performing GridSearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'max_depth'\n",
    "max_depth = np.arange(5, 75, 5)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'Random Forest accuracy for different values of max_depth', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      max_depth, \n",
    "                      'max_depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'max_depth' seems to increase the accuracy of the training set between the values 0 and 30, which will add to the high variance problem. Also, increasing 'min_samples_split' does seem to decrease the accuracy of the cross-validation set between the values 0 and 30. Because an increase in 'max_depth' does almost instantly increase the high variance problem and decrease the accuracy, only the value 5 will be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_split'\n",
    "min_samples_split = np.arange(5, 755, 30)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'Random Forest accuracy for different values of min_samples_split', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_split, \n",
    "                      'min_samples_split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'min_samples_split' seems to lower the accuracy of the training set, which will reduce the high variance problem. Increasing 'min_samples_split' also seems to increase the accuracy of the cross-validation set, with a plateau between de values 300 and 500. The range between 300 and 500 will therefore be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_leaf'\n",
    "min_samples_leaf = np.arange(5, 210, 10)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'Random Forest accuracy for different values of min_samples_leaf', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_leaf, \n",
    "                      'min_samples_leaf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'min_samples_leaf' seems to lower the accuracy of the training set, which will reduce the high variance problem. Increasing 'min_samples_leaf' also seems to increase the accuracy of the cross-validation set, with a plateau between de values 60 and 150. The range between 60 and 150 will therefore be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3. Optimize Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "rf_grid = { 'n_estimators': np.arange(5, 115, 10),\n",
    "            'max_depth': [5],\n",
    "            'min_samples_split': np.arange(300, 520, 20),\n",
    "            'min_samples_leaf': np.arange(60, 165, 15) }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in rf_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=21)\n",
    "rf_grid_search = GridSearchCV(estimator=rf_clf,\n",
    "                             param_grid=rf_grid,\n",
    "                             cv=5,\n",
    "                             verbose=2,\n",
    "                             n_jobs=-1)\n",
    "# Fit the random search model\n",
    "rf_grid_search = rf_grid_search.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the Random Forest classifier with optimized hyperparameters: %0.3f' % (rf_grid_search.best_score_))\n",
    "\n",
    "# Print improvements relative to Random Forest classfier with default hyperparameters\n",
    "improvement = rf_grid_search.best_score_ - rf_clf_default_score\n",
    "print('Improvement relative to default mean cross-validated accuracy: : %0.3f' % (improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Random Forest classifier using the best hyperparameters\n",
    "rf_clf = rf_grid_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(rf_clf, 'Learning Curves of Random Forest (optimized)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule of thumb is: The larger the gap between the cross-validation set and the training the set the higher the variance (overfit). After finetuning the hyperparamters of the Random Forest classifier according to the training data, the cross-validation trend and the training set trend converges. This concludes that the problem of overfitting has been solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_metrics = metrics(y_test, rf_clf.predict(X_test_best));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show improvements relative to the default cross-validated metrics\n",
    "print('Accuracy improvement of: %0.3f' % (rf_clf_metrics[0] - rf_clf_default_metrics[0]))\n",
    "print('F1-score improvement of: %0.3f' % (rf_clf_metrics[1] - rf_clf_default_metrics[1]))\n",
    "print('Precision improvement of: %0.3f' % (rf_clf_metrics[2] - rf_clf_default_metrics[2]))\n",
    "print('Recall improvement of: %0.3f' % (rf_clf_metrics[3] - rf_clf_default_metrics[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2. Support Vector Machine (SVM)\n",
    "*Multiclass as One-Vs-One*<br><br>\n",
    "This time the Support Vector Machine (SVM) classifier will be used to predict the job satisfaction using the selected features.\n",
    "First, the default SVM classifier will trained on the training set and evaltuated.\n",
    "After the evaluation, a second SVM will be used to select the optimal hyperparameters.\n",
    "The Random Forest classifier containing the optimal hyperparamaters will be evaluated on high variance (overfitting) and high bias (underfitting).<br>\n",
    "The following hyperparameters will be optimized:\n",
    "+ C: Penalty parameter C of the error term.\n",
    "+ gamma: Kernel coefficient.\n",
    "+ kernel: The kernel type to be used in the algorithm ('rbf', 'poly')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_default = SVC(random_state=21)\n",
    "svm_clf_default_score = np.sum(cross_val_score(svm_clf_default, X_train_best, y_train, cv=5, n_jobs=-1)) / 5\n",
    "\n",
    "print('Mean cross-validated score of SVM with default parameters: %0.3f' % (svm_clf_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_default.fit(X_train_best, y_train)\n",
    "svm_clf_default_metrics = metrics(y_test, svm_clf_default.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(SVC(kernel='rbf', random_state=21), 'Learning Curves of SVM with RBF kernel (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default SVM classifier with the RBF kernel doesn't seem to overfit or underfit the data. The gap between the cross-validations scores and the traing scores are almost non-non-existent. The goal therefore is to only improve the current accuracy and F1 score by finetuning the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(SVC(kernel='linear', random_state=21), 'Learning Curves of SVM with Linear kernel (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default SVM classifier with the Linear kernel performs way worse than the SVM classifier with the RBF kernel. This can conclude that the data is more non-linear than it is linear seperatable. For this reason, the Linear kernel won't be used for further evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'C'\n",
    "C = np.logspace(0, 3, 4)\n",
    "plot_validation_curve(SVC(kernel='rbf', random_state=21),\n",
    "                      'Accuracy for different values of C with RBF kernel', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      C, \n",
    "                      'C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'C' seems to increase the accuracy of the training set between the values 1000 and 10000. It also looks like the line is still increasing after the value of 10000. The reason that bigger values won't be chosen is because of the processing time it would take and the change of overfitting. The level of C is the level of how much the kernel is trying to fit all the training examples. For these reasons, the values 1000 and 10000 will be chosen when performing GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'gamma'\n",
    "gamma = np.logspace(0, 3, 4)\n",
    "plot_validation_curve(SVC(kernel='rbf', random_state=21),\n",
    "                      'Accuracy for different values of gamma for RBF kernel', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      gamma, \n",
    "                      'gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation set score raises till a gamma value of 100. After this value the cross-validation set score decreases slowly. Also, the training set score keeps raising after the gamme value of 10. This indicates that overfitting can cause an issue if a value is picked above the value of 10 or 100. For these reasons, the values 10 and 100 will be chosen when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(random_state=21, C=1, gamma=10, kernel='rbf')\n",
    "svm_clf.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_score = np.sum(cross_val_score(svm_clf, X_train_best, y_train, cv=5)) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best cross-validated score\n",
    "print('Mean cross-validated score of the best estimator: %0.3f' % (svm_clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(svm_clf, 'Learning Curves of SVM (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_metrics = metrics(y_test, svm_clf.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy improvement of: %0.3f' % (svm_clf_metrics[0] - svm_clf_default_metrics[0]))\n",
    "print('F1-score improvement of: %0.3f' % (svm_clf_metrics[1] - svm_clf_default_metrics[1]))\n",
    "print('Precision improvement of: %0.3f' % (svm_clf_metrics[2] - svm_clf_default_metrics[2]))\n",
    "print('Recall improvement of: %0.3f' % (svm_clf_metrics[3] - svm_clf_default_metrics[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3. Naive Bayes (GaussianNB & MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf_default = GaussianNB()\n",
    "gnb_clf_default_score = np.sum(cross_val_score(gnb_clf_default, X_train_best, y_train, cv=5)) / 5\n",
    "\n",
    "print('Mean cross-validated score of random forest with default parameters: %0.3f' % (gnb_clf_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf_default.fit(X_train_best, y_train)\n",
    "gnb_clf_default_metrics = metrics(y_test, gnb_clf_default.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(GaussianNB(), 'Learning Curves of Gaussian Naive Bayes (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf_default = MultinomialNB()\n",
    "mnb_clf_default_score = np.sum(cross_val_score(mnb_clf_default, X_train_best, y_train, cv=5)) / 5\n",
    "\n",
    "print('Mean cross-validated score of random forest with default parameters: %0.3f' % (mnb_clf_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf_default.fit(X_train_best, y_train)\n",
    "mnb_clf_default_metrics = metrics(y_test, mnb_clf_default.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(MultinomialNB(), 'Learning Curves of Gaussian Naive Bayes (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finetune\n",
    "No hyperparameters to finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = gnb_clf_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics\n",
    "Same as show above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.4. Bonus: RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_metrics(y_test, y_pred, show=True):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mean_abs_err = mean_absolute_error(y_test, y_pred)\n",
    "    mean_sqr_err = mean_squared_error(y_test, y_pred)\n",
    "    if show:\n",
    "        print('R2 on test set: %0.3f' % (r2))\n",
    "        print('Mean Absolute Error on test set: %0.3f' % (mean_abs_err))\n",
    "        print('Mean Squared Error on test set: %0.3f' % (mean_sqr_err))\n",
    "    return r2, mean_abs_err, mean_sqr_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_reg_default = RandomForestRegressor(random_state=21)\n",
    "rf_reg_default_score = np.sum(cross_val_score(rf_reg_default, X_train_best, y_train, cv=5, scoring='r2')) / 5\n",
    "\n",
    "print('R2 score of Polynomial Regression with default parameters: %0.3f' % (pr_reg_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_default.fit(X_train_best, y_train)\n",
    "rf_reg_default_reg_metrics = reg_metrics(y_test, rf_reg_default.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(rf_reg_default.predict(X_test_best))\n",
    "rf_reg_default_metrics = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(RandomForestRegressor(random_state=21), 'Learning Curves of SVM with RBF kernel (default)',\n",
    "                    X_train_best, y_train,\n",
    "                    scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter evaluation\n",
    "Show the validation curve of different hyperparamethers of the Random Forest classifiers (for both training and cross-validation set). The results will be used to select a range of hyperparameter to perform GridSearch on, which will fine tune the hyperparameters more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'n_estimators'\n",
    "n_estimators = np.arange(5, 505, 50)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'Accuracy for different values of n_estimator', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      n_estimators, \n",
    "                      'n_estimators',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'max_depth'\n",
    "max_depth = np.arange(5, 75, 5)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'Accuracy for different values of max_depth', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      max_depth, \n",
    "                      'max_depth',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_split'\n",
    "min_samples_split = np.arange(5, 850, 30)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'Accuracy for different values of min_samples_split', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_split, \n",
    "                      'min_samples_split',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_leaf'\n",
    "min_samples_leaf = np.arange(5, 250, 10)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'Accuracy for different values of min_samples_leaf', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_leaf, \n",
    "                      'min_samples_leaf',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.arange(5, 115, 10)\n",
    "max_depth = [5]\n",
    "min_samples_split = np.arange(400, 850, 50)\n",
    "min_samples_leaf = np.arange(100, 275, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "rf_reg_grid = { 'n_estimators': n_estimators,\n",
    "           'max_depth': max_depth,\n",
    "           'min_samples_split': min_samples_split,\n",
    "           'min_samples_leaf': min_samples_leaf }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in rf_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(random_state=21)\n",
    "rf_reg_grid_search = GridSearchCV(estimator=rf_reg,\n",
    "                             param_grid=rf_reg_grid,\n",
    "                             cv=5,\n",
    "                             verbose=2,\n",
    "                             n_jobs=-1,\n",
    "                             scoring='r2')\n",
    "# Fit the random search model\n",
    "rf_reg_grid_search = rf_reg_grid_search.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best cross-validated score\n",
    "print('R2 score of the best estimator: %0.3f' % (rf_reg_grid_search.best_score_))\n",
    "print('Improvement relative to default R2 score: : %0.3f' % (rf_reg_grid_search.best_score_ - pr_reg_default_score))\n",
    "\n",
    "# Show best parameters\n",
    "best_rf_reg_params = rf_reg_grid_search.best_params_\n",
    "best_rf_reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Random Forest classifier using the best hyperparameters\n",
    "rf_reg = rf_reg_grid_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(rf_reg, 'Learning Curves of SVM with RBF kernel (default)',\n",
    "                    X_train_best, y_train,\n",
    "                    scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_reg_metrics = reg_metrics(y_test, rf_reg.predict(X_test_best));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(rf_reg.predict(X_test_best))\n",
    "rf_reg_metrics = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2 score improvement of: %0.3f' % (rf_reg_reg_metrics[0] - rf_reg_default_reg_metrics[0]))\n",
    "print('Mean Absolute Error improvement of: %0.3f' % (rf_reg_reg_metrics[1] - rf_reg_default_reg_metrics[1]))\n",
    "print('Mean Squared Error improvement of: %0.3f' % (rf_reg_reg_metrics[2] - rf_reg_default_reg_metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Accuracy improvement of: %0.3f' % (rf_reg_metrics[0] - rf_reg_default_metrics[0]))\n",
    "print('F1-score improvement of: %0.3f' % (rf_reg_metrics[1] - rf_reg_default_metrics[1]))\n",
    "print('Precision improvement of: %0.3f' % (rf_reg_metrics[2] - rf_reg_default_metrics[2]))\n",
    "print('Recall improvement of: %0.3f' % (rf_reg_metrics[3] - rf_reg_default_metrics[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5. Bonus: Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_metrics(y_test, y_pred, show=True):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    homogeneity = homogeneity_score(y_test, y_pred)\n",
    "    completeness = completeness_score(y_test, y_pred)\n",
    "    v_measure = v_measure_score(y_test, y_pred)\n",
    "    if show:\n",
    "        print('Accuracy on test set: %0.3f' % (accuracy))\n",
    "        print('Homogeneity score on test set: %0.3f' % (homogeneity))\n",
    "        print('Completeness score on test set: %0.3f' % (completeness))\n",
    "        print('V-Measure score on test set: %0.3f' % (v_measure))\n",
    "    return accuracy, homogeneity, completeness, v_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_most_accurate(y_test, y_pred):\n",
    "    labels = np.zeros_like(y_pred)\n",
    "    for i in range(10):\n",
    "        mask = (y_pred == i)\n",
    "        labels[mask] = mode(y_test[mask])[0]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_clt = KMeans(n_clusters=7, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_clt.fit(X_train_best, y_train)\n",
    "y_pred = perm_most_accurate(y_test, km_clt.predict(X_test_best))\n",
    "km_clt_metrics = clt_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('RandomForest', rf_clf),\n",
    "               ('SVM (Gaussian)', svm_clf),\n",
    "               ('NaiveBayes (Gaussian)', nb_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(classifiers, X_test, y_test):\n",
    "    y_pred = []\n",
    "    accs = [metrics(y_test, tup[1].predict(X_test), show=False)[0] for tup in classifiers]\n",
    "    preds = [tup[1].predict(X_test) for tup in classifiers]\n",
    "    for i in range(len(preds[0])):\n",
    "        y_pred.append([])\n",
    "        for j in range(len(preds)):\n",
    "            y_pred[i].append(preds[j][i])\n",
    "        y_pred[i] = stats.mode(y_pred[i]).mode[0]\n",
    "        # Different votes: look at the best classifier\n",
    "        if y_pred[i] > 1:\n",
    "            y_pred[i] = preds[accs.index(max(accs))][i]\n",
    "    return y_pred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = majority_vote(classifiers, X_test_best, y_test)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_metrics = metrics(y_test, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Compare results of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(results, rowIndex, title, y_label):\n",
    "    # Plot all accuracy scores thus far\n",
    "    plt.figure(figsize=(8, 4), dpi=75)\n",
    "\n",
    "    ratios = results.columns\n",
    "    y_pos = np.arange(len(ratios))\n",
    "    performance = results.iloc[rowIndex].values\n",
    "    plt.bar(y_pos, performance, align='center')\n",
    "    plt.xticks(y_pos, ratios)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, clf in classifiers:\n",
    "    results[name] = metrics(y_test, clf.predict(X_test_best), show=False)\n",
    "results['Ensemble'] = ensemble_metrics\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(results, 0, 'Accuracy of different classifiers', 'Accuracy in %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(results, 1, 'F1-score of different classifiers', 'F1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(results, 2, 'Precision of different classifiers', 'Precision in %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(results, 3, 'Recall of different classifiers', 'Recall in %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
