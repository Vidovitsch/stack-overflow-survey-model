{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Job Satisfaction of Software Developers\n",
    "In this research project a classification model will be created that tries to predict the Job Satisfaction of Software Developers using the survey results from the Stack Overflow survey of 2018.<br>\n",
    "The Job Satisfaction has 7 levels:\n",
    "1. Extremely satisfied\n",
    "2. Moderately satisfied\n",
    "3. Slightly satisfied\n",
    "4. Neither satisfied nor dissatisfied\n",
    "5. Slightly dissatisfied\n",
    "6. Moderately dissatisfied\n",
    "7. Extremely dissatisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Describing the dataset\n",
    "[Stack Overflow](https://stackoverflow.com/) is a website where you can ask and answer software related questions. It is a platform where millions of programmers, software developers, software engineers, etc. meet every day to learn form each other. Stack Overflow itself is aware of the enormous popularity of their platform and for this reason they keep a annual survey to get general insight about the average software engineer in relation to his/her field of work.\n",
    "\n",
    "Every year the results of the survey will get published on their website (cleaned and in csv format). Multiple datasets (one for each year since 2015) are available for analysis. For this project the survey results of 2018 will be used exclusively. The main reason for this choice is recency and the completeness of the results. The 2018 survey results were filled in by around 100.000 software developers, most of which answered 129 different questions. These questions are about job satisfaction, salary, favourite programming languages, weekly exercise, company size, etc. This large variety of questions provides a source of interesting research opportunities.\n",
    "\n",
    "**Source of the dataset**<br />\n",
    "Stack Overflow Developer Survey 2018 (186 MB): https://www.kaggle.com/stackoverflow/stack-overflow-2018-developer-survey\n",
    "\n",
    "\n",
    "**Data description:**<br />\n",
    "The Stack Overflow survey results of 2018 has in total 98855 rows and 129 columns. Some of these columns consist of only numerical data like 'Salary' and 'ConvertedSalary', while all the other columns are categorical (nominal or ordinal). The categorical columns are devidable over three data types:\n",
    "- Values denoted in text. E.g. 'Yes', 'No', 'United States', 'Employed part-time', etc.\n",
    "- Values denoted in ';' seperated lists. E.g. 'Python;Java;C#', 'Windows;Linux;, etc.\n",
    "- Values denoted in numbers. E.g. 1, 2, 3, 4, etc. (for rankings)\n",
    "\n",
    "Textual input can't be interpreted easily by the average Machine Learning algorithm. Therefore, preprocessing of the original dataset is needed, so it can be used for further analysis. A [notebook](./dataset_preprocessing.ipynb) is created that is dedicted to preprocessing the Stack Overflow survey dataset in the following ways:\n",
    "- Drop rows with missing values in the column 'JobSatisfaction'. The column 'JobSatisfaction' is the target value that will be used for analysis. It is not desirable to have missing values for a target feature, because the value NaN doesn't refer to valid classification value.\n",
    "- Drop unimportant columns. Some columns can be left out because they have no correlation with the target column 'JobSatisfaction', are redundant or have too many missing values (35% or higher).\n",
    "- Preprocess values dentoed in ';' seperated lists. List values such as 'Python;Java;C#' can't be used as input for a Machine Learning algorithm. First, the value has to be numerical. Second, numerification of the ';' value as is will result a unique class for every unique list. It is instead needed to get a unique class for every language present in the list.\n",
    "- Encode text to numerical values. Text isn't easy to interpret for Machine Learning algorithms. To solve this problem all text-formatted values will be converted to numerical values. Nominal values are encoded with One Hot Encoding, while ordinal values are encoded with manually added labels.\n",
    "- Impute missing values. A lot of data is missing, this missing data can be imputed with statistical values (e.g. mean, mode, etc.)\n",
    "\n",
    "The above steps will result in a preprocessed data set with 69276 rows and 623 columns.<br />\n",
    "The data will be tranformed as follows:<br />\n",
    "\n",
    "| Student | Programming Language | Country        |\n",
    "|:-------:|:--------------------:|:--------------:|\n",
    "| Yes     | Python;Java;C#       | Kenya          |\n",
    "| No      | Python;C#            | United Kingdom |\n",
    "| Yes     | Java;C#              | United States  |\n",
    "\n",
    "| Student | Python | Java | C# | Country%Kenya | Country%United Kingdom | Country%United States |\n",
    "|:-------:|:------:|:----:|:--:|:-------------:|:----------------------:|:---------------------:|\n",
    "| 1       | 1      | 1    | 1  | 1             | 0                      | 0                     |\n",
    "| 0       | 1      | 0    | 1  | 0             | 1                      | 0                     |\n",
    "| 1       | 0      | 1    | 1  | 0             | 0                      | 1                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining research\n",
    "Research will be conducted on the job satisfaction of software developers. The dataset, as described above, will be used to create a classifaction model that predicts the job statisfaction of software developers. The following research question will be answered:\n",
    "\n",
    "**Can an accurate model be created, given the features denoted in the survey, to predict the job satisfaction of software developers?**\n",
    "\n",
    "The model will be seen as accurate if at least 90% of the predictions are the same as the target values (column 'JobSatisfaction'). This means that the algorithm should predict one of the seven labels (extremely satisfied, moderately satisfied, slightly satisfied, neither satisfied nor dissatisfied, slightly dissatisfied, moderately dissatisfied, extremely dissatisfied) with an accuracy of 90%.\n",
    "<br><br>*Why accurcacy in contrast to precision and recall?*\n",
    "<br>First, this case is a balanced classification problem. This is a problem where the number of observations belonging to one class is about the same as those belonging to the other classes. For example, it won't happen that 99.99% of all software developers are extremely satisfied with their jobs. For inbalanced classification models, accuracy will be more invalid and recall and precision are better metrics to look at because recall and precision look at the quality of the positive predictions.\n",
    "<br>Although precision and recall won't be used as main optimization metric, it will be used for comparisons at the end of the research.\n",
    "\n",
    "**Salary and career satisfaction are the main influencors of job satisfaction, and is therefore responsible for a high accuracy classification model.**\n",
    "\n",
    "This hypothesis will be either approved or rejected accoring to the reseach results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset exploration\n",
    "Initial exploration of the data gives insight of the data itself and a better intuiting while conducting the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# disable chained assignments\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Import the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed dataset\n",
    "so_survey = pd.read_csv('./dataset/so_survey_prepped.csv')\n",
    "\n",
    "# Import the mappings for decoding purposes\n",
    "so_mappings = pd.read_csv('./dataset/so_survey_mappings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it a binary classification problem\n",
    "#so_survey = so_survey[so_survey['JobSatisfaction'] != 3]\n",
    "#so_survey['JobSatisfaction'].loc[so_survey['JobSatisfaction'] < 3] = 0\n",
    "#so_survey['JobSatisfaction'].loc[so_survey['JobSatisfaction'] > 3] = 1\n",
    "#so_survey['JobSatisfaction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>YearsCoding</th>\n",
       "      <th>YearsCodingProf</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>CareerSatisfaction</th>\n",
       "      <th>AssessJob1</th>\n",
       "      <th>AssessJob2</th>\n",
       "      <th>AssessJob3</th>\n",
       "      <th>AssessJob4</th>\n",
       "      <th>AssessJob5</th>\n",
       "      <th>...</th>\n",
       "      <th>EducationParents%Bachelor’s degree (BA, BS, B.Eng., etc.)</th>\n",
       "      <th>EducationParents%Master’s degree (MA, MS, M.Eng., MBA, etc.)</th>\n",
       "      <th>EducationParents%Other doctoral degree (Ph.D, Ed.D., etc.)</th>\n",
       "      <th>EducationParents%Primary/elementary school</th>\n",
       "      <th>EducationParents%Professional degree (JD, MD, etc.)</th>\n",
       "      <th>EducationParents%Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)</th>\n",
       "      <th>EducationParents%Some college/university study without earning a degree</th>\n",
       "      <th>EducationParents%They never completed any formal education</th>\n",
       "      <th>Dependents%No</th>\n",
       "      <th>Dependents%Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CompanySize  YearsCoding  YearsCodingProf  JobSatisfaction  \\\n",
       "0          2.0          1.0                1                6   \n",
       "1          7.0          9.0                5                1   \n",
       "2          2.0          7.0                2                5   \n",
       "\n",
       "   CareerSatisfaction  AssessJob1  AssessJob2  AssessJob3  AssessJob4  \\\n",
       "0                   6        10.0         7.0         8.0         1.0   \n",
       "1                   3         1.0         7.0        10.0         8.0   \n",
       "2                   5         9.0         9.0         8.0         1.0   \n",
       "\n",
       "   AssessJob5       ...        \\\n",
       "0         2.0       ...         \n",
       "1         2.0       ...         \n",
       "2         1.0       ...         \n",
       "\n",
       "   EducationParents%Bachelor’s degree (BA, BS, B.Eng., etc.)  \\\n",
       "0                                                1.0           \n",
       "1                                                1.0           \n",
       "2                                                1.0           \n",
       "\n",
       "   EducationParents%Master’s degree (MA, MS, M.Eng., MBA, etc.)  \\\n",
       "0                                                0.0              \n",
       "1                                                0.0              \n",
       "2                                                0.0              \n",
       "\n",
       "   EducationParents%Other doctoral degree (Ph.D, Ed.D., etc.)  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "\n",
       "   EducationParents%Primary/elementary school  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "\n",
       "   EducationParents%Professional degree (JD, MD, etc.)  \\\n",
       "0                                                0.0     \n",
       "1                                                0.0     \n",
       "2                                                0.0     \n",
       "\n",
       "   EducationParents%Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)  \\\n",
       "0                                                0.0                                                     \n",
       "1                                                0.0                                                     \n",
       "2                                                0.0                                                     \n",
       "\n",
       "   EducationParents%Some college/university study without earning a degree  \\\n",
       "0                                                0.0                         \n",
       "1                                                0.0                         \n",
       "2                                                0.0                         \n",
       "\n",
       "   EducationParents%They never completed any formal education  Dependents%No  \\\n",
       "0                                                0.0                     0.0   \n",
       "1                                                0.0                     0.0   \n",
       "2                                                0.0                     1.0   \n",
       "\n",
       "   Dependents%Yes  \n",
       "0             1.0  \n",
       "1             1.0  \n",
       "2             0.0  \n",
       "\n",
       "[3 rows x 623 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first three entries of so_survey data frame\n",
    "so_survey.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>YearsCoding</th>\n",
       "      <th>YearsCodingProf</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>CareerSatisfaction</th>\n",
       "      <th>TimeFullyProductive</th>\n",
       "      <th>AgreeDisagree1</th>\n",
       "      <th>AgreeDisagree2</th>\n",
       "      <th>AgreeDisagree3</th>\n",
       "      <th>NumberMonitors</th>\n",
       "      <th>...</th>\n",
       "      <th>HypotheticalTools1</th>\n",
       "      <th>HypotheticalTools2</th>\n",
       "      <th>HypotheticalTools3</th>\n",
       "      <th>HypotheticalTools4</th>\n",
       "      <th>HypotheticalTools5</th>\n",
       "      <th>HoursComputer</th>\n",
       "      <th>HoursOutside</th>\n",
       "      <th>SkipMeals</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fewer than 10 employees</td>\n",
       "      <td>0-2 years</td>\n",
       "      <td>0-2 years</td>\n",
       "      <td>Extremely dissatisfied</td>\n",
       "      <td>Extremely dissatisfied</td>\n",
       "      <td>Less than a month</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Not at all interested</td>\n",
       "      <td>Less than 1 hour</td>\n",
       "      <td>Less than 30 minutes</td>\n",
       "      <td>Never</td>\n",
       "      <td>I don't typically exercise</td>\n",
       "      <td>Under 18 years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 to 19 employees</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>Moderately dissatisfied</td>\n",
       "      <td>Moderately dissatisfied</td>\n",
       "      <td>One to three months</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>A little bit interested</td>\n",
       "      <td>1 - 4 hours</td>\n",
       "      <td>30 - 59 minutes</td>\n",
       "      <td>1 - 2 times per week</td>\n",
       "      <td>1 - 2 times per week</td>\n",
       "      <td>18 - 24 years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>6-8 years</td>\n",
       "      <td>6-8 years</td>\n",
       "      <td>Slightly dissatisfied</td>\n",
       "      <td>Slightly dissatisfied</td>\n",
       "      <td>Three to six months</td>\n",
       "      <td>Neither Agree nor Disagree</td>\n",
       "      <td>Neither Agree nor Disagree</td>\n",
       "      <td>Neither Agree nor Disagree</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>Somewhat interested</td>\n",
       "      <td>5 - 8 hours</td>\n",
       "      <td>1 - 2 hours</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>25 - 34 years old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CompanySize YearsCoding YearsCodingProf  \\\n",
       "0  Fewer than 10 employees   0-2 years       0-2 years   \n",
       "1       10 to 19 employees   3-5 years       3-5 years   \n",
       "2       20 to 99 employees   6-8 years       6-8 years   \n",
       "\n",
       "           JobSatisfaction       CareerSatisfaction  TimeFullyProductive  \\\n",
       "0   Extremely dissatisfied   Extremely dissatisfied    Less than a month   \n",
       "1  Moderately dissatisfied  Moderately dissatisfied  One to three months   \n",
       "2    Slightly dissatisfied    Slightly dissatisfied  Three to six months   \n",
       "\n",
       "               AgreeDisagree1              AgreeDisagree2  \\\n",
       "0           Strongly disagree           Strongly disagree   \n",
       "1                    Disagree                    Disagree   \n",
       "2  Neither Agree nor Disagree  Neither Agree nor Disagree   \n",
       "\n",
       "               AgreeDisagree3 NumberMonitors         ...          \\\n",
       "0           Strongly disagree              1         ...           \n",
       "1                    Disagree              2         ...           \n",
       "2  Neither Agree nor Disagree              3         ...           \n",
       "\n",
       "        HypotheticalTools1       HypotheticalTools2       HypotheticalTools3  \\\n",
       "0    Not at all interested    Not at all interested    Not at all interested   \n",
       "1  A little bit interested  A little bit interested  A little bit interested   \n",
       "2      Somewhat interested      Somewhat interested      Somewhat interested   \n",
       "\n",
       "        HypotheticalTools4       HypotheticalTools5     HoursComputer  \\\n",
       "0    Not at all interested    Not at all interested  Less than 1 hour   \n",
       "1  A little bit interested  A little bit interested       1 - 4 hours   \n",
       "2      Somewhat interested      Somewhat interested       5 - 8 hours   \n",
       "\n",
       "           HoursOutside             SkipMeals                    Exercise  \\\n",
       "0  Less than 30 minutes                 Never  I don't typically exercise   \n",
       "1       30 - 59 minutes  1 - 2 times per week        1 - 2 times per week   \n",
       "2           1 - 2 hours  3 - 4 times per week        3 - 4 times per week   \n",
       "\n",
       "                  Age  \n",
       "0  Under 18 years old  \n",
       "1   18 - 24 years old  \n",
       "2   25 - 34 years old  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first three entries of so_mappings data frame\n",
    "so_mappings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create decode  and encode function\n",
    "In advance, a generic decode and encode function will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(labels, column_name, decoder=so_mappings):\n",
    "    \"\"\" Decodes encoded (preprocessed) labes using a decoder.\n",
    "    E.g. [0, 1, 0, 0] for column 'Hobby' => ['Yes', 'No', 'Yes', 'Yes']\n",
    "    \"\"\"\n",
    "    decoded_labels = so_mappings[column_name].values\n",
    "    return [decoded_labels[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, column_name, encoder=so_mappings):\n",
    "    \"\"\" Encoded decoded labes using an encoder.\n",
    "    E.g. ['Yes', 'No', 'Yes', 'Yes'] for column 'Hobby' => [0, 1, 0, 0]\n",
    "    \"\"\"\n",
    "    decoded_labels = so_mappings[column_name].values.tolist()\n",
    "    return [decoded_labels.index(l) for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Distribution of salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data frame with column 'ConvertedSalary' and NaN values filtered out\n",
    "mask = pd.isnull(so_survey['ConvertedSalary']) == False\n",
    "salaries = so_survey['ConvertedSalary'][mask].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot salary distribution\n",
    "plt.figure(figsize=(20,5))\n",
    "kde = sns.kdeplot(salaries, shade=True)\n",
    "kde.set(title='Data distribution of salary', \n",
    "        xlabel='Salary', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of salary appears the be very skewed. To reduce the skew, log transformation can be applied on the salaries. But before we can do this, the salaries with value zero needs to be filtered out (logarithm of zero is impossible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = np.log(salaries[salaries != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot salary distribution (log transformed)\n",
    "plt.figure(figsize=(20,5))\n",
    "kde = sns.kdeplot(salaries, shade=True)\n",
    "kde.set(title='Data distribution of salary (log transformed)', \n",
    "        xlabel='Salary (log transformed)', \n",
    "        ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data distribution has now more the appearance of a gaussian distribution (bell curve shape). Although, the data is still skewed due to the outliers. If the many outliers will cause the classification model to perform badly, the outliers will be removed. This can be done, for example, by pruning the data by $x$ times the standard deviation of the salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Scatter Job Satisfaction and Career Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction = so_survey[['JobSatisfaction', 'CareerSatisfaction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg = sns.regplot(x='JobSatisfaction', y='CareerSatisfaction', data=satisfaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot looks a bit odd because of the classifications in the column JobSatisfaction and CareerSatisfaction. But, the regression line shows that there is a positive correlation between Job Satisfaction and Career Satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Scatter Job Satisfaction and Converted Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_sal = so_survey[['JobSatisfaction', 'ConvertedSalary']]\n",
    "sat_sal['ConvertedSalary'] = np.log(sat_sal['ConvertedSalary'][sat_sal['ConvertedSalary'] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg = sns.regplot(x='JobSatisfaction', y='ConvertedSalary', data=sat_sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter plot looks alos bit odd because of the classifications in the column JobSatisfaction. The regression line shows that there is a small positive correlation between Job Satisfaction and Salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Research strategy\n",
    "The research will be conducted by using following steps:\n",
    "1. Loosely optimize the hyperparameters of a classifier that will be used in the feature selection part. This prevents selecting features with e.g. an overfitted/underfit model.\n",
    "2. Selecting features with the finetuned classifier. (feature selection is necessary since training classifiers with 622 features and more than 69000 rows is extremely time consuming) \n",
    "3. Use the selected features to train and optimize different Machine Learning algorithms.\n",
    "4. Compare the performance of the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target (y) \n",
    "target = 'JobSatisfaction'\n",
    "y = so_survey[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features (X)\n",
    "features = [x for x in so_survey.columns if x != target]\n",
    "X = so_survey[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Perform feature scaling\n",
    "The column 'ConvertedSalary' will be log tranformed to reduce skewness. Also, a min max scaler will be used to scale the features to values between 0 and 1, resulting in all features having values within the same range. This has some benefits:\n",
    "+ All features have the same 'weight'. This will help algorithms like SVM (with Gaussian kernel) and K-means to perform better.\n",
    "+ Speeds up Gradient Descent while training.\n",
    "+ Improves insight in coefficients. If all features have the same 'weight', the resulting coefficients will describe the influence of feature on the target better. This is useful for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the logarithm of 0 is impossible.\n",
    "# For this reason the values of 0 will be replaced by 0.1.\n",
    "X['ConvertedSalary'].loc[(X['ConvertedSalary'] == 0)] = 0.1\n",
    "\n",
    "# Perform log transformation on the values in the column 'ConvertedSalary'\n",
    "X['ConvertedSalary'] = np.log(X['ConvertedSalary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature scaling with min max scaler\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Get training and testing sets\n",
    "The features and target values will be split into training and testing sets.\n",
    "The training set will contain 75% of the dataset (randomly selected rows).\n",
    "The testing set will therefore contain 25% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loosely optimize estimator\n",
    "The Random Forest classifier will be used as an estimator for the feature selection step. This has the following benefits:\n",
    "+ Popular feature selection algorithms like RFE or RFECV are recursively training a classifier. This will take a lot of time. Decision Trees are faster than classifiers such as Neural Networks or Support Vector Machines. \n",
    "+ By using a Random Forest the main drawback of Decision Trees (overfitting the training set) will be (partly) solved.\n",
    "+ It isn't known if the classes are linear separatable. A Random Forest is both a linear and a non-linear classifier.\n",
    "<br><br>The RandomizedSearch method will be used in contrast to GridSearch, because RandomizedSearch doesn't compute all possible computations (hence 'loosely') and is therefore computationally less expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest classifier and RandomizedSearchCV algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: [ 50 100 150 200]\n",
      "max_depth: [5]\n",
      "min_samples_split: [ 50  55  60  65  70  75  80  85  90  95 100]\n",
      "min_samples_leaf: [20 25 30 35 40 45 50]\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid with hyperparameter ranges\n",
    "random_grid = { 'n_estimators': np.arange(50, 250, 50),\n",
    "                'max_depth': [5],\n",
    "                'min_samples_split': np.arange(50, 105, 5),\n",
    "                'min_samples_leaf': np.arange(20, 55, 5) }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in random_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated accuracy of the default estimator: 0.794\n"
     ]
    }
   ],
   "source": [
    "# Train default Random Forest classifier for comparison\n",
    "default_score = np.sum(cross_val_score(RandomForestClassifier(random_state=21), X, y, cv=5)) / 5\n",
    "\n",
    "# Print default cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the default estimator: %0.3f' % (default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Search of optimal set of hyperparameters using 3 fold cross validation and 25 different combinations. \n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=21), \n",
    "                                   param_distributions=random_grid, \n",
    "                                   n_iter=25, \n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=21, \n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  7.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit Random Search on the training set\n",
    "random_search = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'min_samples_split': 55,\n",
       " 'min_samples_leaf': 20,\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best parameters\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated accuracy of the best estimator: 0.753\n",
      "Improvement relative to default mean cross-validated accuracy: : -0.041\n"
     ]
    }
   ],
   "source": [
    "# Print best cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the best estimator: %0.3f' % (random_search.best_score_))\n",
    "\n",
    "# Print improvements relative to Random Forest classfier with default hyperparameters\n",
    "improvement = random_search.best_score_ - default_score\n",
    "print('Improvement relative to default mean cross-validated accuracy: : %0.3f' % (improvement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature selection\n",
    "The datasets contains 622 features and about 69000 rows. Training with such an amount of features can take a very long time for algorithms like SVM (expontential time complexity). The training process becomes much faster by pruning redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. RFECV (Recursive Feature Elimination with Cross-Validation)\n",
    "Recursive Feature Elimination is a method that uses an estimator (in this case a classifier) that assigns weights to features (coefficients). The goal is to recursively select features by considering smaller and smaller sets of features. The least important features are pruned from the training and testing set. Cross Validation is used to make a selection of the best number of features.<br>\n",
    "The estimator that will be used is the Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RFECV algorithm\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RFECV algorithm with the loosely optimized Random Forest classifier\n",
    "f_selector = RFECV(estimator=random_search.best_estimator_ ,\n",
    "                   step=1,\n",
    "                   cv=3,\n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RFECV on the training set\n",
    "f_selector = f_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of features vs. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.plot(range(1, len(f_selector.grid_scores_) + 1), f_selector.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best number of features\n",
    "print('Optimal number of features: %i' % (f_selector.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that shows the ranking of features\n",
    "def create_ranking_df(ranking_list, columns):\n",
    "    ranking = {}\n",
    "    for i in range(len(ranking_list)):\n",
    "        rank = ranking_list[i]\n",
    "        col = columns[i]\n",
    "        if rank in ranking:\n",
    "            ranking[rank].append(col)\n",
    "        else:\n",
    "            ranking[rank] = [col]\n",
    "    ranking = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in ranking.items()]))\n",
    "    return ranking.reindex(sorted(ranking.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show ranking\n",
    "ranking = create_ranking_df(f_selector.ranking_, X.columns)\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Prune redundant featues\n",
    "The selected features will be used to create the new training set and test set.\n",
    "CareerSatisfaction and ConvertedSalary will be added to the selection if they are not selected. This is because the two values are needed to promote or reject the defined hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indeces of best selection of features\n",
    "best_features = [i for i, rank in enumerate(f_selector.ranking_) if rank == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes of 'CareerSatisfaction' and 'ConvertedSalary'\n",
    "satisfaction = [i for i, col in enumerate(X.columns) if col == 'CareerSatisfaction'][0]\n",
    "salary= [i for i, col in enumerate(X.columns) if col == 'ConvertedSalary'][0]\n",
    "\n",
    "# If index is not yet in selection: add it to selection\n",
    "if satisfaction not in best_features: best_features.append(satisfaction)\n",
    "if salary not in best_features: best_features.append(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = X.columns[best_features]\n",
    "X_train_best = X_train[:,best_features]\n",
    "X_test_best = X_test[:,best_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train and optimize different algorithms\n",
    "In this section the following Machine Learning algorithms/methods will be optimized and trained to predict job satisfaction:\n",
    "+ Random Forest (Classifier)\n",
    "+ Support Vector Machine\n",
    "+ Naive Bayes\n",
    "+ Random Forest (Regressor)\n",
    "+ K-means\n",
    "+ Ensemble Learning (combining above algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV algorithm to select best combination of hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import leaning_curve and validation_curve to evaluate trained models\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting learning curves:\n",
    "# Learning curves show the learning rate of the training and \n",
    "# cross-validation set over training examples (m).\n",
    "def plot_learning_curve(estimator, title, X, y, scoring='accuracy'):    \n",
    "    # Fit to get parameters for the learning curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator,\n",
    "        X, y, cv=3, train_sizes=np.linspace(.1, 1.0, 5), scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Get mean and standard deviation for training scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    \n",
    "    # Get mean and standard deviation for cross-validation scores\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # Setup chart\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score (' + scoring + ')')\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color='b')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='r')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='b',\n",
    "             label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='Cross-validation score')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting validation curves:\n",
    "# Validation curves show the learning rate of the training and \n",
    "# cross-validation set over a range of values of a defined hyperparameter.\n",
    "def plot_validation_curve(estimator, title, X, y, param_range, param_name, scoring='accuracy'):\n",
    "    # Fit to get parameters for the validation curve\n",
    "    train_scores, test_scores = validation_curve(estimator,\n",
    "        X, y, cv=3, param_name=param_name, param_range=param_range, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Get mean and standard deviation for training scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "\n",
    "    # Get mean and standard deviation for cross-validation scores\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # Setup chart\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Score (' + scoring + ')')\n",
    "    plt.grid()\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='g', lw=2)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color='r', lw=2)\n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color='g',\n",
    "         label='Training score')\n",
    "    plt.plot(param_range, test_scores_mean, 'o-', color='r',\n",
    "             label='Cross-validation score')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_metrics(y_test, y_pred, show=True):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "    recall = recall_score(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "    if show:\n",
    "        print('Accuracy on test set: %0.3f' % (accuracy))\n",
    "        print('F1-score on test set: %0.3f' % (f1))\n",
    "        print('Precision on test set: %0.3f' % (precision))\n",
    "        print('Recall on test set: %0.3f' % (recall))\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Random Forest (Classifier)\n",
    "*Inherently multiclass*<br><br>\n",
    "The Random Forest classifier is used before when selecting features. This time the Random Forest classifier will be used to predict the job satisfaction using the selected features.\n",
    "First, the default Random Forest classifier will trained on the training set and evaluated.\n",
    "After the evaluation, a second Random Forest will be used to select the optimal hyperparameters.\n",
    "The Random Forest classifier containing the optimal hyperparamaters will be evaluated on high variance (overfitting), high bias (underfitting) and performance based on accuracy.<br>\n",
    "The following hyperparameters will be optimized:\n",
    "+ n_estimators: The number of trees in the forest.\n",
    "+ max_depth: The maximum depth of the tree.\n",
    "+ min_samples_split: The minimum number of samples required to split an internal node.\n",
    "+ min_samples_leaf: The minimum number of samples required to be at a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.1. Training the default Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train default Random Forest classifier for comparison\n",
    "rf_clf_default = RandomForestClassifier(random_state=21)\n",
    "rf_clf_default_score = np.sum(cross_val_score(rf_clf_default, X_train_best, y_train, cv=5)) / 5\n",
    "\n",
    "# Print default cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the Random Forest classifier with default hyperparameters: %0.3f' % (rf_clf_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show default classification metrics\n",
    "rf_clf_default.fit(X_train_best, y_train)\n",
    "rf_clf_default_metrics = clf_metrics(y_test, rf_clf_default.predict(X_test_best));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(RandomForestClassifier(random_state=21),\n",
    "                    'Learning Curves of RF (default)',\n",
    "                    X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high variance problem (overfitted) will occur when using the default Random Forest classifier. The training set starts of with high accuracy (as expected) but the accuracy doesn't decline much as the number of training examples increases. In contrast, the cross-validation accuracy starts off with low accuracy and increases with very small amounts as the number of training examples increases. This high variance problem can be solved by evaluating different hyperparameters of the Random Forest classifier and using the results to optimize the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.2. Evaluate hyperparameters\n",
    "Show the validation curve of different hyperparamethers of the Random Forest classifiers (for both the training and cross-validation set). The results will be used to select a range of hyperparameter to perform Grid Search on, which will optimize the hyperparameters more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'n_estimators'\n",
    "n_estimators = np.arange(5, 505, 50)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'RF accuracy for different values of n_estimator', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      n_estimators, \n",
    "                      'n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'n_estimators' seems to increase the accuracy of the training set between the values 0 and 100, which will add to the high variance problem. Also, increasing 'min_samples_split' doesn't seems to increase the accuracy of the cross-validation set very much. Becuase increasing 'n_estimators' doesn't seem te be necessary, the range between 5 and 100 will be used when performing GridSearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'max_depth'\n",
    "max_depth = np.arange(5, 75, 5)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'RF accuracy for different values of max_depth', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      max_depth, \n",
    "                      'max_depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'max_depth' seems to increase the accuracy of the training set between the values 0 and 30, which will add to the high variance problem. Also, increasing 'min_samples_split' does seem to decrease the accuracy of the cross-validation set between the values 0 and 30. Because an increase in 'max_depth' does almost instantly increase the high variance problem and decrease the accuracy, only the value 5 will be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_split'\n",
    "min_samples_split = np.arange(5, 755, 30)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'RF accuracy for different values of min_samples_split', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_split, \n",
    "                      'min_samples_split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'min_samples_split' seems to lower the accuracy of the training set, which will reduce the high variance problem. Increasing 'min_samples_split' also seems to increase the accuracy of the cross-validation set, with a plateau between de values 300 and 500. The range between 300 and 500 will therefore be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_leaf'\n",
    "min_samples_leaf = np.arange(5, 210, 10)\n",
    "plot_validation_curve(RandomForestClassifier(random_state=21), \n",
    "                      'RF accuracy for different values of min_samples_leaf', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_leaf, \n",
    "                      'min_samples_leaf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'min_samples_leaf' seems to lower the accuracy of the training set, which will reduce the high variance problem. Increasing 'min_samples_leaf' also seems to increase the accuracy of the cross-validation set, with a plateau between de values 60 and 150. The range between 60 and 150 will therefore be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.3. Optimize Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "rf_grid = { 'n_estimators': np.arange(5, 115, 10),\n",
    "            'max_depth': [5],\n",
    "            'min_samples_split': np.arange(300, 520, 20),\n",
    "            'min_samples_leaf': np.arange(60, 165, 15) }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in rf_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=21)\n",
    "rf_grid_search = GridSearchCV(estimator=rf_clf,\n",
    "                              param_grid=rf_grid,\n",
    "                              cv=5,\n",
    "                              verbose=2,\n",
    "                              n_jobs=-1)\n",
    "# Fit the random search model\n",
    "rf_grid_search = rf_grid_search.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the Random Forest classifier with optimized hyperparameters: %0.3f' % (rf_grid_search.best_score_))\n",
    "\n",
    "# Print improvements relative to Random Forest classfier with default hyperparameters\n",
    "improvement = rf_grid_search.best_score_ - rf_clf_default_score\n",
    "print('Improvement relative to default mean cross-validated accuracy: : %0.3f' % (improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Random Forest classifier using the best hyperparameters\n",
    "rf_clf = rf_grid_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(rf_clf, 'Learning Curves of RF (optimized)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule of thumb is: The larger the gap between the cross-validation set and the training the set the higher the variance (overfit). After finetuning the hyperparamters of the Random Forest classifier according to the training data, the cross-validation accuracy and the training set accuracy converges. This concludes that the problem of overfitting has been solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_metrics = clf_metrics(y_test, rf_clf.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show improvements relative to the default classification metrics\n",
    "print('Accuracy improvement of: %0.3f' % (rf_clf_metrics[0] - rf_clf_default_metrics[0]))\n",
    "print('F1-score improvement of: %0.3f' % (rf_clf_metrics[1] - rf_clf_default_metrics[1]))\n",
    "print('Precision improvement of: %0.3f' % (rf_clf_metrics[2] - rf_clf_default_metrics[2]))\n",
    "print('Recall improvement of: %0.3f' % (rf_clf_metrics[3] - rf_clf_default_metrics[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Support Vector Machine\n",
    "*Multiclass as One-Vs-One*<br><br>\n",
    "The Support Vector Machine classifier will be used to predict the job satisfaction using the selected features.\n",
    "First, the default Support Vector Machine classifier will trained on the training set and evaluated.\n",
    "After the evaluation, a second Support Vector Machine classifier will be used to select the optimal hyperparameters.\n",
    "The Support Vector Machine classifier containing the optimal hyperparamaters will be evaluated on high variance (overfitting), high bias (underfitting) and perfomance based on accuracy.<br>\n",
    "The following hyperparameters will be optimized:\n",
    "+ C: Penalty parameter C of the error term.\n",
    "+ gamma: Kernel coefficient.\n",
    "+ kernel: The kernel type to be used in the algorithm ('linear', 'rbf')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Support Vector Machine module\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1. Training the default Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train default Support Vector Machine classifier for comparison\n",
    "svm_clf_default = SVC(random_state=21)\n",
    "svm_clf_default_score = np.sum(cross_val_score(svm_clf_default, X_train_best, y_train, cv=5, n_jobs=-1)) / 5\n",
    "\n",
    "# Print default cross-validated accuracy\n",
    "print('Mean cross-validated accuracy of the Support Vector Machine classifier with default hyperparameters: %0.3f' % (svm_clf_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show default classification metrics\n",
    "svm_clf_default.fit(X_train_best, y_train)\n",
    "svm_clf_default_metrics = clf_metrics(y_test, svm_clf_default.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An initial comparison will be made between a Support Vector Machine using the Linear kernel and one using the Gaussian kerntel. The results of this comparison can give better insight into the nature of the data. Is it linearly seperatable or not? If one kernel outperforms the other, the underperforming kernel will be removed from further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curve using the gaussian (rbf) kernel\n",
    "plot_learning_curve(SVC(kernel='rbf', random_state=21),\n",
    "                    'Learning Curves of SVM with Guassian kernel (default)',\n",
    "                    X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default Support Vector Machine classifier with the Gaussian kernel doesn't seem to overfit or underfit the data. The gap between the cross-validations scores and the traing scores are almost non-non-existent. The goal therefore is to only improve the current accuracy by optimizing the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(SVC(kernel='linear', random_state=21),\n",
    "                    'Learning Curves of SVM with Linear kernel (default)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default Support Vector Machine classifier with the Linear kernel performs way than the Support Vector Machine classifier with the Gaussian kernel. This concludes that the data is more non-linearly than it is linearly seperatable. For this reason the Linear kernel won't be used for further evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2. Evaluate hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the validation curve of different hyperparamethers of the Support Vector Machine classifiers (for both the training and cross-validation set). The results will be used to select a range of hyperparameter to perform Grid Search on, which will optimize the hyperparameters more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'C'\n",
    "C = np.logspace(-1, 3, 5)\n",
    "plot_validation_curve(SVC(kernel='rbf', random_state=21),\n",
    "                      'SVM accuracy for different values of C with Gaussian kernel', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      C, \n",
    "                      'C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'C' seems to increase the accuracy of the training set between the values 1 and 10000. It also looks like the line is still increasing after the value of 10000. Although increasing C seems to increase the accuracy, only the value of 1 will be used. The values 10 and higher result in a very long processing time, because the model tries to fit every example with a small margin. The value of 1 will still yield a good accuracy and it performs reasonably fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'gamma'\n",
    "gamma = np.logspace(-1, 3, 5)\n",
    "plot_validation_curve(SVC(kernel='rbf', random_state=21),\n",
    "                      'SVM accuracy for different values of gamma with Gaussian kernel', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      gamma, \n",
    "                      'gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation accuracy raises till a 'gamma' value of 100. After this value the cross-validation set score decreases slowly. Also, the training set score keeps raising after the 'gamma' value of 10. This indicates that overfitting can cause an issue if a value is picked above the value of 10 or 100. Only the value of 10 will be chosen because a bigger value will take alot of time to process and this value still yield a reasonable good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.3. Optimize Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search will not be necessary for this optimization part. The evaluation part gave a good indication of which values to use as the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "svm_grid = { 'C': 1,\n",
    "             'gamma': 10,\n",
    "             'kernel': 'rbf' }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in svm_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Support Vector Machine with selected hyperparameter values\n",
    "svm_clf = SVC(random_state=21,\n",
    "              C=svm_grid['C'],\n",
    "              gamma=svm_grid['gamma'],\n",
    "              kernel=svm_grid['kernel'])\n",
    "svm_clf = svm_clf.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print cross-validated accuracy\n",
    "svm_clf_score = np.sum(cross_val_score(svm_clf, X_train_best, y_train, cv=5)) / 5\n",
    "print('Mean cross-validated score of the best estimator: %0.3f' % (svm_clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(svm_clf, 'Learning Curves of SVM (optimized)', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has become slightly more overfitted because the gap between the training accuracy and the cross-validation accuracy is slightly bigger. This gap is still small enough to not pose a overfitting problem. All in all, it converges nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_metrics = clf_metrics(y_test, svm_clf.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show improvements relative to the default classification metrics\n",
    "print('Accuracy improvement of: %0.3f' % (svm_clf_metrics[0] - svm_clf_default_metrics[0]))\n",
    "print('F1-score improvement of: %0.3f' % (svm_clf_metrics[1] - svm_clf_default_metrics[1]))\n",
    "print('Precision improvement of: %0.3f' % (svm_clf_metrics[2] - svm_clf_default_metrics[2]))\n",
    "print('Recall improvement of: %0.3f' % (svm_clf_metrics[3] - svm_clf_default_metrics[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Naive Bayes\n",
    "*Inherently multiclass*<br><br>\n",
    "The Naive Bayes classifier will be used to predict the job satisfaction using the selected features.\n",
    "First, the Gaussian Naive Bayes classifier will trained on the training set and evaluated.\n",
    "After the evaluation, the Multinomial Naive Bayes classifier will be trained on the training set and evaluated.\n",
    "Both versions of the Naive Bayes classifier will be compared. The best performing classifier will be chosen. There will be no optimization part because Naive Bayes has no hyperparameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Naive Bayes modules\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1. Training the Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gaussian Naive Bayes classifier for comparison\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf_score = np.sum(cross_val_score(gnb_clf, X_train_best, y_train, cv=5)) / 5\n",
    "\n",
    "# Print cross-validated accuracy of Gaussian Naive Bayes classifier\n",
    "print('Mean cross-validated accuracy of the Gaussian Naive Bayes classifier: %0.3f' % (gnb_clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classification metrics\n",
    "gnb_clf.fit(X_train_best, y_train)\n",
    "gnb_clf_metrics = clf_metrics(y_test, gnb_clf.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(GaussianNB(), 'Learning Curves of Gaussian Naive Bayes', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes permorms reasonably good despite its simplicity. The cross-validation accuracy and training accuracy have almost no gap between eachother, which concludes that there is no overfit. But, the accuracy of both sets decline while the traning examples grow. This could indicate a small underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2. Training the Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multinomial Naive Bayes classifier for comparison\n",
    "mnb_clf = MultinomialNB()\n",
    "mnb_clf_score = np.sum(cross_val_score(mnb_clf, X_train_best, y_train, cv=5)) / 5\n",
    "\n",
    "# Print cross-validated accuracy of Multinomial Naive Bayes classifier\n",
    "print('Mean cross-validated score of the Multinomial Naive Bayes: %0.3f' % (mnb_clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classification metrics\n",
    "mnb_clf.fit(X_train_best, y_train)\n",
    "mnb_clf_metrics = clf_metrics(y_test, mnb_clf.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(MultinomialNB(), 'Learning Curves of Multinomial Naive Bayes', X_train_best, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes permorms worse than the Gaussian Naive Bayes. The cross-validation accuracy and training accuracy have almost no gap between eachother, which concludes that there is no overfit. There is alsno no sign of rapid accuracy decline, which concludes there is also no underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3. Optimize Naive Bayes classifier\n",
    "No hyperparameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = gnb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_metrics = clf_metrics(y_test, nb_clf.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4. Random Forest (Regressor)\n",
    "*Regressor*<br><br>\n",
    "The Random Forest regressor will be used to predict the job satisfaction using the selected features.\n",
    "First, the default Random Forest regressor will trained on the training set and evaluated.\n",
    "After the evaluation, a second Random Forest regressor will be used to select the optimal hyperparameters.\n",
    "The Random Forest regressor containing the optimal hyperparamaters will be evaluated on high variance (overfitting), high bias (underfitting) and performance based on the R2 score.<br>\n",
    "The following hyperparameters will be optimized:\n",
    "+ n_estimators: The number of trees in the forest.\n",
    "+ max_depth: The maximum depth of the tree.\n",
    "+ min_samples_split: The minimum number of samples required to split an internal node.\n",
    "+ min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "<br><br>\n",
    "Two sets of metrics will be used to measure performance. The first set contains the R2 score, Mean Absolute Error and Mean Squared Error. The second set contains the same metrics as the classifiers (accuracy, f1, recall, precision). The accuracy will be measure by rounding the predicted values of the regressor to represent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest Regressor module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_metrics(y_test, y_pred, show=True):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mean_abs_err = mean_absolute_error(y_test, y_pred)\n",
    "    mean_sqr_err = mean_squared_error(y_test, y_pred)\n",
    "    if show:\n",
    "        print('R2 on test set: %0.3f' % (r2))\n",
    "        print('Mean Absolute Error on test set: %0.3f' % (mean_abs_err))\n",
    "        print('Mean Squared Error on test set: %0.3f' % (mean_sqr_err))\n",
    "    return r2, mean_abs_err, mean_sqr_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.1. Training the default Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train default Random Forest regressor for comparison\n",
    "rf_reg_default = RandomForestRegressor(random_state=21)\n",
    "rf_reg_default_score = np.sum(cross_val_score(rf_reg_default, X_train_best, y_train, cv=5, scoring='r2')) / 5\n",
    "\n",
    "# Print default cross-validated R2 score\n",
    "print('Mean cross-validated R2 score of the Random Forest regressor with default hyperparameters: %0.3f' % (rf_reg_default_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show default cross-validated regression metrics\n",
    "rf_reg_default.fit(X_train_best, y_train)\n",
    "rf_reg_default_reg_metrics = reg_metrics(y_test, rf_reg_default.predict(X_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show default cross-validated classification metrics\n",
    "y_pred = np.round(rf_reg_default.predict(X_test_best))\n",
    "rf_reg_default_metrics = clf_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plot_learning_curve(RandomForestRegressor(random_state=21), 'Learning Curves of RF regressor (default)',\n",
    "                    X_train_best, y_train,\n",
    "                    scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high variance problem (overfitted) will occur when using the default Random Forest regressor. The training set starts of with high accuracy (as expected) but the accuracy doesn't decline much as the number of training examples increases. In contrast, the cross-validation accuracy starts off with low accuracy and increases with very small amounts as the number of training examples increases. This high variance problem can be solved by evaluating different hyperparameters of the Random Forest regressor and using the results to optimize the regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.2. Evaluate hyperparameters\n",
    "Show the validation curve of different hyperparamethers of the Random Forest regressor (for both training and cross-validation set). The results will be used to select a range of hyperparameter to perform GridSearch on, which will fine tune the hyperparameters more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'n_estimators'\n",
    "n_estimators = np.arange(5, 505, 50)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'RF accuracy for different values of n_estimator', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      n_estimators, \n",
    "                      'n_estimators',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'n_estimators' seems to increase the accuracy of the training set between the values 0 and 100, which will add to the high variance problem. Also, increasing 'min_samples_split' doesn't seems to increase the accuracy of the cross-validation set very much. Becuase increasing 'n_estimators' doesn't seem te be necessary, the range between 5 and 100 will be used when performing GridSearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'max_depth'\n",
    "max_depth = np.arange(5, 75, 5)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'RF accuracy for different values of max_depth', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      max_depth, \n",
    "                      'max_depth',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'max_depth' seems to increase the accuracy of the training set between the values 0 and 30, which will add to the high variance problem. Also, increasing 'min_samples_split' does seem to decrease the accuracy of the cross-validation set between the values 0 and 30. Because an increase in 'max_depth' does almost instantly increase the high variance problem and decrease the accuracy, only the value 5 will be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_split'\n",
    "min_samples_split = np.arange(5, 850, 30)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'RF accuracy for different values of min_samples_split', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_split, \n",
    "                      'min_samples_split',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'min_samples_split' seems to lower the accuracy of the training set, which will reduce the high variance problem. Increasing 'min_samples_split' also seems to increase the accuracy of the cross-validation set, with a plateau between de values 500 and 850. The range between 500 and 850 will therefore be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show validation curve for different values of hyperparameter 'min_samples_leaf'\n",
    "min_samples_leaf = np.arange(5, 250, 10)\n",
    "plot_validation_curve(RandomForestRegressor(random_state=21), \n",
    "                      'RF accuracy for different values of min_samples_leaf', \n",
    "                      X_train_best, \n",
    "                      y_train, \n",
    "                      min_samples_leaf, \n",
    "                      'min_samples_leaf',\n",
    "                      scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the hyperparameter 'min_samples_leaf' seems to lower the accuracy of the training set, which will reduce the high variance problem. Increasing 'min_samples_leaf' also seems to increase the accuracy of the cross-validation set, with a plateau between de values 100 and 250. The range between 100 and 250 will therefore be used when performing GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.3. Optimize Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "rf_reg_grid = { 'n_estimators': np.arange(5, 115, 10),\n",
    "                'max_depth': [5],\n",
    "                'min_samples_split': np.arange(400, 850, 50),\n",
    "                'min_samples_leaf': np.arange(100, 275, 25) }\n",
    "# Print grid\n",
    "[print('%s: %s' % x) for x in rf_reg_grid.items()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(random_state=21)\n",
    "rf_reg_grid_search = GridSearchCV(estimator=rf_reg,\n",
    "                                  param_grid=rf_reg_grid,\n",
    "                                  cv=5,\n",
    "                                  verbose=2,\n",
    "                                  n_jobs=-1,\n",
    "                                  scoring='r2')\n",
    "# Fit the random search model\n",
    "rf_reg_grid_search = rf_reg_grid_search.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "rf_reg_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best cross-validated score\n",
    "print('R2 score of the best estimator: %0.3f' % (rf_reg_grid_search.best_score_))\n",
    "print('Improvement relative to default R2 score: : %0.3f' % (rf_reg_grid_search.best_score_ - rf_reg_default_score))\n",
    "\n",
    "# Show best parameters\n",
    "best_rf_reg_params = rf_reg_grid_search.best_params_\n",
    "best_rf_reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Random Forest regressor using the best hyperparameters\n",
    "rf_reg = rf_reg_grid_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(rf_reg, 'Learning Curves of RF regressor (optimized)',\n",
    "                    X_train_best, y_train,\n",
    "                    scoring='r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finetuning the hyperparamters of the Random Forest regressor according to the training data, the cross-validation accuracy and the training set accuracy converges. This concludes that the problem of overfitting has been solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_reg_metrics = reg_metrics(y_test, rf_reg.predict(X_test_best));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show improvements relative to the default cross-validated regression metrics\n",
    "print('R2 score improvement of: %0.3f' % (rf_reg_reg_metrics[0] - rf_reg_default_reg_metrics[0]))\n",
    "print('Mean Absolute Error improvement of: %0.3f' % (rf_reg_reg_metrics[1] - rf_reg_default_reg_metrics[1]))\n",
    "print('Mean Squared Error improvement of: %0.3f' % (rf_reg_reg_metrics[2] - rf_reg_default_reg_metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(rf_reg.predict(X_test_best))\n",
    "rf_reg_metrics = clf_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show improvements relative to the default cross-validated classification metrics\n",
    "print('Accuracy improvement of: %0.3f' % (rf_reg_metrics[0] - rf_reg_default_metrics[0]))\n",
    "print('F1-score improvement of: %0.3f' % (rf_reg_metrics[1] - rf_reg_default_metrics[1]))\n",
    "print('Precision improvement of: %0.3f' % (rf_reg_metrics[2] - rf_reg_default_metrics[2]))\n",
    "print('Recall improvement of: %0.3f' % (rf_reg_metrics[3] - rf_reg_default_metrics[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5. K-means\n",
    "*Clustering*<br><br>\n",
    "K-means will be used to predict the job satisfaction using the selected features.\n",
    "This unsupervised clustering algorithm will search for 7 clusters (target feature has 7 labels). The outputted labels will be permuted. The permutation with the highest performance (accurayc) will be be choses as prediction.<br>\n",
    "K-means has no hyperparameters that could be optimzed. K-means can't also be plotted with a Learning Curve because of it's unsupervised nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import K-means module\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Import metrics\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_metrics(y_test, y_pred, show=True):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    homogeneity = homogeneity_score(y_test, y_pred)\n",
    "    completeness = completeness_score(y_test, y_pred)\n",
    "    v_measure = v_measure_score(y_test, y_pred)\n",
    "    if show:\n",
    "        print('Accuracy on test set: %0.3f' % (accuracy))\n",
    "        print('Homogeneity score on test set: %0.3f' % (homogeneity))\n",
    "        print('Completeness score on test set: %0.3f' % (completeness))\n",
    "        print('V-Measure score on test set: %0.3f' % (v_measure))\n",
    "    return accuracy, homogeneity, completeness, v_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_most_accurate(y_test, y_pred):\n",
    "    labels = np.zeros_like(y_pred)\n",
    "    for i in range(10):\n",
    "        mask = (y_pred == i)\n",
    "        labels[mask] = mode(y_test[mask])[0]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5.1. Training K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-means with 7 clusters (target featuer has 7 labels)\n",
    "km_clt = KMeans(n_clusters=7, random_state=21)\n",
    "km_clt = km_clt.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5.2. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show clustering metrics\n",
    "y_pred = perm_most_accurate(y_test, km_clt.predict(X_test_best))\n",
    "km_clt_metrics = clt_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classifier metrics\n",
    "km_clt_metrics = clf_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6. Ensemble Learning\n",
    "Ensemble Learning will be used to combine the predictive power of all the above Machine Learning algorithms: Random Forest (Classifier), Support Vector Machine with Gaussian kernel, Gaussian Naive Bayes, Random Forest (Regressor) and K-means. All algorithms will do a prediction on the test set and the majority of the predictions will be chosen. If it's an even vote, the prediction will be chosen of the best permorming algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(y_predictions, accuracies):\n",
    "    y_pred = []\n",
    "    for i in range(len(y_predictions[0])):\n",
    "        y_pred.append([])\n",
    "        for j in range(len(y_predictions)):\n",
    "            y_pred[i].append(y_predictions[j][i])\n",
    "        y_pred[i] = stats.mode(y_pred[i]).mode[0]\n",
    "        # Different votes: look at the best classifier\n",
    "        if y_pred[i] > 1:\n",
    "            y_pred[i] = y_predictions[accuracies.index(max(accuracies))][i]\n",
    "    return y_pred          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.1. Training Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = []\n",
    "# Get prediction of Random Forest (Classifier)\n",
    "y_predictions.append(rf_clf.predict(X_test_best))\n",
    "# Get prediction of Support Vector Machine with Gaussian kernel\n",
    "y_predictions.append(svm_clf.predict(X_test_best))\n",
    "# Get prediction of Gaussian Naive Bayes\n",
    "y_predictions.append(nb_clf.predict(X_test_best))\n",
    "# Get prediction of Random Forest (Regressor)\n",
    "y_predictions.append(np.round(rf_reg.predict(X_test_best)))\n",
    "# Get prediction of K-means\n",
    "y_predictions.append(perm_most_accurate(y_test, km_clt.predict(X_test_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "# Get accuracy of Random Forest (Classifier)\n",
    "accuracies.append(rf_clf_metrics[0])\n",
    "# Get accuracy of Support Vector Machine with Gaussian kernel\n",
    "accuracies.append(svm_clf_metrics[0])\n",
    "# Get accuracy of Gaussian Naive Bayes\n",
    "accuracies.append(nb_clf_metrics[0])\n",
    "# Get accuracy of Random Forest (Regressor)\n",
    "accuracies.append(rf_reg_metrics[0])\n",
    "# Get accuracy of K-means\n",
    "accuracies.append(km_clt_metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vote(y_predictions, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.2. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_metrics = clf_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare results of Machine Learning algorithms/methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(df, x, y, title):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    ax = sns.barplot(x=x, y=y, data=results)\n",
    "    ax.set_title(title);\n",
    "    rects = ax.patches\n",
    "    labels = np.round(results[y] * 1000) / 1000\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, height, label,\n",
    "                ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Setup metrics for all algorithms/methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([rf_clf_metrics,\n",
    "              svm_clf_metrics,\n",
    "              nb_clf_metrics,\n",
    "              rf_reg_metrics,\n",
    "              km_clt_metrics,\n",
    "              ensemble_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = { 'algorithms/methods': ['RF (Classifier)', 'SVM', 'Naive Bayes', 'RF (Regressor)', 'K-means', 'Ensemble'],\n",
    "            'accuracy': m[:,0],\n",
    "            'f1-score': m[:,1],\n",
    "            'precision': m[:,2],\n",
    "            'recall': m[:,3] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Accuracy comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "plot_bar_chart(results, 'algorithms/methods', 'accuracy', 'Accuracy of different algorithms/methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. F1-score comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "plot_bar_chart(results, 'algorithms/methods', 'f1-score', 'F1-score of different algorithms/methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4. Precision comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "plot_bar_chart(results, 'algorithms/methods', 'precision', 'Precision of different algorithms/methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5. Recall comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "plot_bar_chart(results, 'algorithms/methods', 'recall', 'Recall of different algorithms/methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1. Research question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can an accurate model be created, given the features denoted in the survey, to predict the job satisfaction of software developers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accurate model is defined as a model that has an accuracy of above 90%. None of the optimized algorithms/methods was able to reach this level of accuracy. The Random Forest Classifier comes closest with an accuracy of 47%. This is no way near the 90% but when given it some thought, it isn't too bad either. There are seven labels to predict which, chosen randomly, yields an average accuracy of 14%. This means that the Random Forest Classifier predicts much more accurate than choosing labels at random.<br>\n",
    "But still, the research question has to be answered as a negative. It is not possible create an accuracte (90%) model that predicts the level of Job Satisfaction using the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salary and career satisfaction are the main influencors of job satisfaction, and is therefore responsible for a high accuracy classification model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the feature selection part, an inidication was given of the top most important features. The feature 'CareerSatisfaction' became number 1 at having the moest influence on the level of Job Satisfaction, together with 'JobSearchStatus%I am actively looking for a job', 'JobSearchStatus%I am not interested in new job opportunities' and 'JobSearchStatus%I’m not actively looking, but I am open to new opportunities'. The feature 'ConvertedSalary' ended up on the third place, which isn't that bad when selecting from 622 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.1. Get coefficients\n",
    "Because all features were scaled within the same range (between 0 and 1) at the start, the coefficients can be used to measure and compare the influence of the different features. Although, only the Random Forest (Regressor) algorithm can provide these coeffictients. This regressor didn't yield the best results, but should have measured the importances of the different features. Only the coefficients of the selected features will be shown, because they contain both Career Satisfaction and Converted Salary and they contain the other top influencing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = { 'features': feature_labels,\n",
    "          'coefs': rf_reg.feature_importances_ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the top features are all job related and career satisfaction is the biggest influencor (by far) on job satisfaction among them. Converted salary is much less important with a coefficient of just 0.007 in contrast to the number 1 coefficient of 0.781. The concludes that the hypothesis can be rejected. Career Satisfaction is indeed the biggest influencor, but Conver Salary isn't, while the hypothesis stated that both are the main influencors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
